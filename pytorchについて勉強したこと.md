# PyTorchによるディープラーニング実装の流れ

1. 前処理、後処理、ネットワークモデルの入出力を確認
    >画像だったらリサイズ,要素の順番(チャネル、高さ、幅の順番)の調整,RGBの標準化など
2. Datasetの作成
   >```torch.utils.data.Dataset```クラスを継承して、入力データと対応するラベルをペアにして保持したクラスを作り、前処理クラスのインスタントを与えてデータ読み込み時に自動で前処理を行うように設定すると楽。Datasetは訓練、検証、テストデータそれぞれについて作る。
3. DataLoaderの作成
   >DataLoaderはDatasetからどうやってデータを取り出すのかを設定するクラス。```torch.utils.data.Dataloader```をそのまま使う。ディープラーニングではミニバッチ学習を行って複数のデータを同時にDatasetaから取り出してNNを学習させることがデフォルト。Dataset同様訓練、検証、テストデータごとにDataLoaderを作れば入力データに関する準備は終了。
4. ネットワークモデルの作成
   >NNは自分で作る場合と学習済みモデルをロードして使うケース、学習済みモデルをベースに自分で変更を加えるケースがある。
5. forwardの定義,損失関数の定義,最適化手法の設定
   >順伝播を定義し、誤差逆伝搬のための損失関数も定義する。その次にNNのパラメータを学習させるための最適化手法を設定。誤差逆伝搬によって得たパラメータの誤差に対する勾配を用いてパラメータを更新する。
6. 学習/検証
    >epochごとに訓練データでの性能と検証データでの性能を確認。検証データで性能が向上しなくなった後は訓練データに対する過学習に陥るのでその時点で学習を終了させる(early stopping)
7. テストデータで推論
----

# 備忘録

## model.train()とmodel.eval()

dropoutやbatchnormなど、訓練時と推論時で挙動が異なる層がある。これらの層はネットワークの訓練時のみ機能し、推論時には機能する必要のない。この使い分けをmodel.train(),model.eval()で行い、それぞれ訓練モード、推論モードという。

## batch size

バッチサイズが小さいとデータに敏感になる。でかいとそこまで影響を受けない
[batch_sizeの調整](https://teratail.com/questions/246310) によると

- バッチサイズが大きいほど、GPU の消費メモリが増えるので、大きくしすぎると、メモリ不足でエラーになります。
- バッチサイズが大きすぎると、局所解に陥りやすくなり、学習結果が悪くなるかもしれません。

## Batch NormとDropoutを併用するときの順番

- Dense or Conv
- Batch Norm
- Activation
- Dropout

[参考ページ](https://jp.quora.com/%E6%AD%A3%E5%89%87%E5%8C%96-%E3%83%89%E3%83%AD%E3%83%83%E3%83%97%E3%82%A2%E3%82%A6%E3%83%88-%E3%83%90%E3%83%83%E3%83%81-%E5%B1%A4-%E6%AD%A3%E8%A6%8F%E5%8C%96-%E9%87%8D%E3%81%BF%E3%81%AE%E5%88%9D%E6%9C%9F%E5%8C%96)

