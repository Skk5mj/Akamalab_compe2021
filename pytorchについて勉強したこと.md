# PyTorchによるディープラーニング実装の流れ

1. 前処理、後処理、ネットワークモデルの入出力を確認
    >画像だったらリサイズ,要素の順番(チャネル、高さ、幅の順番)の調整,RGBの標準化など
2. Datasetの作成
   >```torch.utils.data.Dataset```クラスを継承して、入力データと対応するラベルをペアにして保持したクラスを作り、前処理クラスのインスタントを与えてデータ読み込み時に自動で前処理を行うように設定すると楽。Datasetは訓練、検証、テストデータそれぞれについて作る。
3. DataLoaderの作成
   >DataLoaderはDatasetからどうやってデータを取り出すのかを設定するクラス。```torch.utils.data.Dataloader```をそのまま使う。ディープラーニングではミニバッチ学習を行って複数のデータを同時にDatasetaから取り出してNNを学習させることがデフォルト。Dataset同様訓練、検証、テストデータごとにDataLoaderを作れば入力データに関する準備は終了。
4. ネットワークモデルの作成
   >NNは自分で作る場合と学習済みモデルをロードして使うケース、学習済みモデルをベースに自分で変更を加えるケースがある。
5. forwardの定義,損失関数の定義,最適化手法の設定
   >順伝播を定義し、誤差逆伝搬のための損失関数も定義する。その次にNNのパラメータを学習させるための最適化手法を設定。誤差逆伝搬によって得たパラメータの誤差に対する勾配を用いてパラメータを更新する。
6. 学習/検証
    >epochごとに訓練データでの性能と検証データでの性能を確認。検証データで性能が向上しなくなった後は訓練データに対する過学習に陥るのでその時点で学習を終了させる(early stopping)
7. テストデータで推論
----

# 備忘録

## model.train()とmodel.eval()

dropoutやbatchnormなど、訓練時と推論時で挙動が異なる層がある。これらの層はネットワークの訓練時のみ機能し、推論時には機能する必要のない。この使い分けをmodel.train(),model.eval()で行い、それぞれ訓練モード、推論モードという。

## 